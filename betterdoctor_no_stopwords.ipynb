{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "from sklearn import feature_extraction\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# docbios = joblib.load('docbios.pkl')\n",
    "# docnames = joblib.load('docnames.pkl')\n",
    "docdict = joblib.load('docdict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for d in docnames[0:10]:\n",
    "#     print d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print docbios[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1899\n"
     ]
    }
   ],
   "source": [
    "print len(docdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing null descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# docnames.index('Brian Anziska, MD')\n",
    "\n",
    "# docbios = np.array(docbios)\n",
    "\n",
    "# emptybios = []\n",
    "# emptybios.append(np.where(docbios==''))\n",
    "# print len(emptybios)\n",
    "\n",
    "# emptybios = np.array(emptybios[0][0])\n",
    "\n",
    "# print len(docnames)\n",
    "# print len(docbios)\n",
    "\n",
    "# print len(emptybios)\n",
    "\n",
    "# print len(docnames)-len(emptybios)\n",
    "\n",
    "# new_docnames = np.delete(docnames, emptybios)\n",
    "# new_docbios = np.delete(docbios, emptybios)\n",
    "\n",
    "# print len(docnames)\n",
    "# print len(docbios)\n",
    "\n",
    "# docnames = new_docnames\n",
    "# docbios = new_docbios\n",
    "\n",
    "# len(np.unique(docnames))\n",
    "\n",
    "# 2505-1899"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# docdict = defaultdict(list)\n",
    "\n",
    "# for name, bio in zip(docnames, docbios):\n",
    "#     docdict[name] = bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Ludmila Davidov, MD is one of the country's most highly ranked doctors. Her specialties include psychiatry and she currently treats patients in Flushing, New York, Rego park, New York, and Whitestone, New York.  Dr. Davidov completed medical school at Tajik State Medical University Named After Abuali Ibn Sino and is licensed to see patients in New York.  Based on an in-depth analysis of Dr. Davidov's credentials, experience and network, she has been found to be among the 20% of doctors nationwide.  Dr. Davidov has been found to hold one or more active medical licenses, and successfully passed a malpractice history screening.\n",
      "\n",
      "I am a neurologist with specialty training in neuro-oncology who sees patients at Memorial Sloan-Kettering facilities in both New York City and Basking Ridge, New Jersey. I treat patients with primary brain tumors and patients with neurological complications of systemic cancer. As a neuro-oncologist, I provide continuity of care for those patients with primary CNS malignancies and coordinate the multidisciplinary management team consisting of neurosurgeons and radiation oncologists. I actively participate in clinical trials at Memorial Sloan-Kettering, including those through the North American Brain Tumor Consortium, in order to evaluate novel chemotherapy, biological, and molecular treatments for patients with malignant brain tumors.\n"
     ]
    }
   ],
   "source": [
    "print docdict['Ludmila Davidov, MD']\n",
    "print\n",
    "print docdict['Igor Gavrilovic, MD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#joblib.dump(docdict,'docdict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2691-2051"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stopwords, stemming and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n"
     ]
    }
   ],
   "source": [
    "print len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your']\n"
     ]
    }
   ],
   "source": [
    "print stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here he defines a tokenizer and stemmer which returns the set of stems in the text that it is passed\n",
    "\n",
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize_only(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#not super pythonic, no, not at all.\n",
    "#use extend so it's a big flat list of vocab\n",
    "totalvocab_stemmed = []\n",
    "totalvocab_tokenized = []\n",
    "for i in docdict.values():\n",
    "    allwords_stemmed = tokenize_and_stem(i) #for each item in 'synopses', tokenize/stem\n",
    "    totalvocab_stemmed.extend(allwords_stemmed) #extend the 'totalvocab_stemmed' list\n",
    "    \n",
    "    allwords_tokenized = tokenize_only(i)\n",
    "    totalvocab_tokenized.extend(allwords_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 135761 items in vocab_frame\n"
     ]
    }
   ],
   "source": [
    "vocab_frame = pd.DataFrame({'words': totalvocab_tokenized}, index = totalvocab_stemmed)\n",
    "print 'there are ' + str(vocab_frame.shape[0]) + ' items in vocab_frame'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dr.</th>\n",
       "      <td>dr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ludmila</th>\n",
       "      <td>ludmila</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>davidov</th>\n",
       "      <td>davidov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>md</th>\n",
       "      <td>md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words\n",
       "dr.          dr.\n",
       "ludmila  ludmila\n",
       "davidov  davidov\n",
       "md            md\n",
       "is            is"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           words\n",
      "dr.          dr.\n",
      "ludmila  ludmila\n",
      "davidov  davidov\n",
      "md            md\n",
      "is            is\n"
     ]
    }
   ],
   "source": [
    "print vocab_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.58 s, sys: 114 ms, total: 6.69 s\n",
      "Wall time: 9.49 s\n",
      "(1899, 61508)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                   use_idf=True,\n",
    "                                   tokenizer=tokenize_only, ngram_range=(2,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(docdict.values()) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "terms = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u\"'s adult\",\n",
       " u\"'s adult long-term\",\n",
       " u\"'s advisory\",\n",
       " u\"'s advisory committee\",\n",
       " u\"'s affairs\",\n",
       " u\"'s affairs medical\",\n",
       " u\"'s areas\",\n",
       " u\"'s areas of\",\n",
       " u\"'s best\",\n",
       " u\"'s best doctors\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#terms_np = np.array(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print (np.nan in terms_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#'' in terms_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61508\n"
     ]
    }
   ],
   "source": [
    "print len(terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 1899)\n"
     ]
    }
   ],
   "source": [
    "print dist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1899, 61508)\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.15 s, sys: 148 ms, total: 1.3 s\n",
      "Wall time: 1.42 s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "n = 3\n",
    "km = KMeans(n_clusters=n)\n",
    "\n",
    "%time km.fit(tfidf_matrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(km,  'doc_cluster_nostopwords.pkl')\n",
    "\n",
    "# km = joblib.load('doc_cluster.pkl')\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### hacky attempt at reading level"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Fleschâ€“Kincaid grade level (fkgl) = 0.39 * (total words/ total sentences) + 11.8 (total syllables/total words) - 15.59"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In the first text, there is an average of 2.83 letters per syllable. I will use letters in place of syllables, by dividing letters/word by 2.83 to get an approximation of syllables/word. This is making the assumption that every bio has the same approximate ratio of letters to syllable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentlen = []\n",
    "wordlen = []\n",
    "fkgl  = []\n",
    "counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 119, 532)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "sentlen = [nltk.sent_tokenize(d) for d in docdict.values()]\n",
    "wordlen = [[nltk.word_tokenize(t) for t in bio] for bio in sentlen]\n",
    "for dr in wordlen:\n",
    "    sentence_cnt = len(dr)\n",
    "    word_cnt = 0\n",
    "    letter_cnt = 0\n",
    "    for sentence in dr:\n",
    "        word_cnt += len(sentence)\n",
    "        for word in sentence:\n",
    "            letter_cnt += len(word)\n",
    "    counts.append((sentence_cnt, word_cnt, letter_cnt))\n",
    "    \n",
    "print(counts[0])\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except ZeroDivisionError:\n",
    "        return np.nan\n",
    "\n",
    "fkgl = [catch(lambda: 0.39 * (dr[1]/dr[0]) + 11.8 * (dr[2]/dr[1])/2.83 - 15.59) \\\n",
    "        for dr in counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fkgl.count(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fkgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.332615256703388"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fkgl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.35116607773851"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(fkgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.826548881036516"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(fkgl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-103-9a0048e03273>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-103-9a0048e03273>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print len(docdict.keys())\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print len(docdict.keys())\n",
    "print len(docdict.values())\n",
    "print len(fkgl)\n",
    "print len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = { 'name': docdict.keys(), 'bio': docdict.values(), 'flesch_kincaid': fkgl, 'cluster': clusters }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135761"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(docs, index = [clusters] , columns = ['name', 'flesch_kincaid', 'bio', 'cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1335\n",
       "1     389\n",
       "2     175\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    12.579876\n",
       "1    12.591125\n",
       "2    23.717654\n",
       "Name: flesch_kincaid, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = df['flesch_kincaid'].groupby(df['cluster']) #groupby cluster for aggregation purposes\n",
    "\n",
    "grouped.mean() #average flesch_kincaid per cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "0    12.085147\n",
       "1    12.443783\n",
       "2    23.112517\n",
       "Name: flesch_kincaid, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_clusters = len(pd.unique(df['cluster']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'became', u'a', u'fellow']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[7048].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab_frame.ix[terms[7048].split(\" \")].values.tolist()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lapidus md'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[33679].encode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'lapidus', u'md']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms[33679].split(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#vocab_frame.ix[terms[33679].split(\" \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "\n",
      "Cluster 0 words: patients in,\n",
      " medical licenses,\n",
      " active medical,\n",
      " active medical licenses,\n",
      " york dr.,\n",
      " new york dr.,\n",
      "\n",
      "\n",
      "Cluster 1 words: none found,\n",
      " passed a background,\n",
      " has successfully,\n",
      " has successfully passed,\n",
      " for malpractice,\n",
      " for malpractice history,\n",
      "\n",
      "\n",
      "Cluster 2 words: psychiatry neurology,\n",
      " psychiatry psychiatry,\n",
      " psychiatry psychiatry neurology,\n",
      " medicine psychiatry neurology,\n",
      " medicine psychiatry,\n",
      " neurology diagnostic,\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "print(\"Top terms per cluster:\")\n",
    "print()\n",
    "#sort cluster centers by proximity to centroid\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(num_clusters):\n",
    "    print(\"Cluster %d words:\" % i, end='')\n",
    "    \n",
    "    for ind in order_centroids[i, :6]: #replace 6 with n words per cluster\n",
    "        try:\n",
    "            print(' %s' % terms[ind].encode('utf-8', 'ignore'), end=',')\n",
    "            print()\n",
    "        except AttributeError as e:\n",
    "            print(\"AttributeError\")\n",
    "    print() #add whitespace\n",
    "    print() #add whitespace\n",
    "    \n",
    "#     print(\"Cluster %d titles:\" % i, end='')\n",
    "#     for title in df.ix[i]['name'].values.tolist():\n",
    "#         print(' %s,' % title, end='')\n",
    "#     print() #add whitespace\n",
    "#     print() #add whitespace\n",
    "    \n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster0 = df.ix[0]\n",
    "cluster1 = df.ix[1]\n",
    "cluster2 = df.ix[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>flesch_kincaid</th>\n",
       "      <th>bio</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ludmila Davidov, MD</td>\n",
       "      <td>12.332615</td>\n",
       "      <td>Dr. Ludmila Davidov, MD is one of the country'...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faiq Hameedi, MD</td>\n",
       "      <td>9.976244</td>\n",
       "      <td>Specializing in psychiatry, Dr. Faiq Hameedi, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hersha Diaz, PSYD</td>\n",
       "      <td>11.019929</td>\n",
       "      <td>Dr. Hersha Diaz, PSYD specializes in psycholog...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Paula Marcus, MD</td>\n",
       "      <td>10.896992</td>\n",
       "      <td>Dr. Paula Marcus, MD specializes in psychiatry...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Igor Gavrilovic, MD</td>\n",
       "      <td>19.305265</td>\n",
       "      <td>I am a neurologist with specialty training in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  flesch_kincaid  \\\n",
       "0  Ludmila Davidov, MD       12.332615   \n",
       "0     Faiq Hameedi, MD        9.976244   \n",
       "0    Hersha Diaz, PSYD       11.019929   \n",
       "0     Paula Marcus, MD       10.896992   \n",
       "0  Igor Gavrilovic, MD       19.305265   \n",
       "\n",
       "                                                 bio  cluster  \n",
       "0  Dr. Ludmila Davidov, MD is one of the country'...        0  \n",
       "0  Specializing in psychiatry, Dr. Faiq Hameedi, ...        0  \n",
       "0  Dr. Hersha Diaz, PSYD specializes in psycholog...        0  \n",
       "0  Dr. Paula Marcus, MD specializes in psychiatry...        0  \n",
       "0  I am a neurologist with specialty training in ...        0  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'name', u'flesch_kincaid', u'cluster'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cluster0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc_cluster2.pkl',\n",
       " 'doc_cluster2.pkl_01.npy',\n",
       " 'doc_cluster2.pkl_02.npy',\n",
       " 'doc_cluster2.pkl_03.npy',\n",
       " 'doc_cluster2.pkl_04.npy',\n",
       " 'doc_cluster2.pkl_05.npy']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(cluster0, 'doc_cluster0.pkl')\n",
    "joblib.dump(cluster1, 'doc_cluster1.pkl')\n",
    "joblib.dump(cluster2, 'doc_cluster2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  name  flesch_kincaid  \\\n",
      "0  Ludmila Davidov, MD       12.332615   \n",
      "\n",
      "                                                 bio  cluster  \n",
      "0  Dr. Ludmila Davidov, MD is one of the country'...        0  \n",
      "Dr. Ludmila Davidov, MD is one of the country's most highly ranked doctors. Her specialties include psychiatry and she currently treats patients in Flushing, New York, Rego park, New York, and Whitestone, New York.  Dr. Davidov completed medical school at Tajik State Medical University Named After Abuali Ibn Sino and is licensed to see patients in New York.  Based on an in-depth analysis of Dr. Davidov's credentials, experience and network, she has been found to be among the 20% of doctors nationwide.  Dr. Davidov has been found to hold one or more active medical licenses, and successfully passed a malpractice history screening.\n",
      "\n",
      "                  name  flesch_kincaid  \\\n",
      "0  Igor Gavrilovic, MD       19.305265   \n",
      "\n",
      "                                                 bio  cluster  \n",
      "0  I am a neurologist with specialty training in ...        0  \n",
      "I am a neurologist with specialty training in neuro-oncology who sees patients at Memorial Sloan-Kettering facilities in both New York City and Basking Ridge, New Jersey. I treat patients with primary brain tumors and patients with neurological complications of systemic cancer. As a neuro-oncologist, I provide continuity of care for those patients with primary CNS malignancies and coordinate the multidisciplinary management team consisting of neurosurgeons and radiation oncologists. I actively participate in clinical trials at Memorial Sloan-Kettering, including those through the North American Brain Tumor Consortium, in order to evaluate novel chemotherapy, biological, and molecular treatments for patients with malignant brain tumors.\n"
     ]
    }
   ],
   "source": [
    "print(df[df['name']=='Ludmila Davidov, MD'])\n",
    "print(docdict['Ludmila Davidov, MD'])\n",
    "print()\n",
    "print(df[df['name']=='Igor Gavrilovic, MD'])\n",
    "print(docdict['Igor Gavrilovic, MD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Sharon Lee, MD MDMPH treats patients in Somerville, Massachusetts, specializing in aerospace medicine, environmental preventive medicine, occupational medicine, preventive medical toxicology, preventive medicine, preventive sports medicine, undersea and hyperbaric medicine, dentist dental public health, and preventive medicine clinical informatics.  Dr. Lee is licensed to treat patients in Massachusetts and New York.  In addition to having active medical licenses, Dr. Lee has been found during an automated background check to be clear of any malpractice history and holds one or more active medical licenses.\n",
      "\n",
      "Dr. Carol Bernstein, MD practices medicine at New york, New York and specializes in addiction psychiatry, child & adolescent psychiatry, clinical neurophysiology, psychiatry, psychiatry & neurology behavioral neurology & neuropsychiatry, psychiatry & neurology diagnostic neuroimaging, psychiatry & neurology forensic psychiatry, psychiatry & neurology hospice and palliative medicine, psychiatry & neurology psychosomatic medicine, and psychiatry & neurology pain medicine.  Dr. Bernstein is licensed to practice medicine at New York.  In addition to having active medical licenses, Dr. Bernstein has passed an automated background check which looked at elements including medical license status and malpractice screening (no history found).\n"
     ]
    }
   ],
   "source": [
    "print(docdict['Sharon Lee, MD'])\n",
    "print()\n",
    "print(docdict['Carol Bernstein, MD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-f4b1d16f5a7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvocab_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "vocab_frame.ix[terms[2].split(' ')].values.tolist()[360][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
